{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "demo_adversarial_debiasing.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFj8HJw33sDq",
        "colab_type": "code",
        "outputId": "d37da955-7314-4bf8-edd3-b579ed2081ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubs9SaELzPvQ",
        "colab_type": "text"
      },
      "source": [
        "#### This notebook demonstrates the use of adversarial debiasing algorithm to learn a fair classifier.\n",
        "Adversarial debiasing [1] is an in-processing technique that learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary's ability to determine the protected attribute from the predictions. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit. We will see how to use this algorithm for learning models with and without fairness constraints and apply them on the Adult dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcw9Exlp5sZ_",
        "colab_type": "code",
        "outputId": "f087cc39-f2c6-4360-88c3-93c4de831bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! pip install 'aif360[all]'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting aif360[all]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e9/f2a936a00c65ce7b4d45587a33c4522fabd773f7325d505a87d133a1dabc/aif360-0.3.0-py3-none-any.whl (165kB)\n",
            "\r\u001b[K     |██                              | 10kB 25.4MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 81kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 102kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 112kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 122kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 133kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 143kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 153kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 163kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.0.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.42.0; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (0.48.0)\n",
            "Requirement already satisfied: pytest>=3.5; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (3.6.4)\n",
            "Requirement already satisfied: sphinx; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.8.5)\n",
            "Collecting sphinx-rtd-theme; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/b4/4df37087a1d36755e3a3bfd2a30263f358d2dea21938240fa02313d45f51/sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 29.3MB/s \n",
            "\u001b[?25hCollecting BlackBoxAuditing; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/2e/e2e7166bc78eb599b602ca79ace1ceba2ef83b69a0b708c9a7eb729347bf/BlackBoxAuditing-0.1.54.tar.gz (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 43.5MB/s \n",
            "\u001b[?25hCollecting lime; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/ee/4aaac4cd79f16329746495aca96f8c35f278b5c774eff3358eaa21e1cbf3/lime-0.2.0.0.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 55.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (4.41.1)\n",
            "Requirement already satisfied: jupyter; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.0.0)\n",
            "Collecting adversarial-robustness-toolbox>=1.0.0; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 52.3MB/s \n",
            "\u001b[?25hCollecting tensorflow<2,>=1.13.1; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/36/9a02e27f0ec248b676a380ffe910c1858e3af3027c0d4d513dd0b56a5613/tensorflow-1.15.3-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 106kB/s \n",
            "\u001b[?25hRequirement already satisfied: cvxpy>=1.0; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.0.31)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->aif360[all]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->aif360[all]) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21->aif360[all]) (0.15.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[all]) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[all]) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[all]) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.42.0; extra == \"all\"->aif360[all]) (47.1.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.42.0; extra == \"all\"->aif360[all]) (0.31.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (8.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (1.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (1.12.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (0.7.12)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (1.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (20.4)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (0.15.2)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (2.1.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (2.0.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (2.8.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (2.11.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (2.23.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing; extra == \"all\"->aif360[all]) (2.4)\n",
            "Collecting pillow==5.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime; extra == \"all\"->aif360[all]) (0.16.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (7.5.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (4.10.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (5.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (5.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (4.7.4)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (5.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (0.34.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 51.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (3.2.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.1.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.29.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (0.9.0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0; extra == \"all\"->aif360[all]) (2.0.7.post1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0; extra == \"all\"->aif360[all]) (0.70.9)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0; extra == \"all\"->aif360[all]) (2.1.2)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0; extra == \"all\"->aif360[all]) (0.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx; extra == \"all\"->aif360[all]) (1.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx; extra == \"all\"->aif360[all]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx; extra == \"all\"->aif360[all]) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx; extra == \"all\"->aif360[all]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx; extra == \"all\"->aif360[all]) (2.9)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->BlackBoxAuditing; extra == \"all\"->aif360[all]) (4.4.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime; extra == \"all\"->aif360[all]) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime; extra == \"all\"->aif360[all]) (2.4.1)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter; extra == \"all\"->aif360[all]) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter; extra == \"all\"->aif360[all]) (5.0.6)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter; extra == \"all\"->aif360[all]) (3.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter; extra == \"all\"->aif360[all]) (4.3.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter; extra == \"all\"->aif360[all]) (5.3.4)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter; extra == \"all\"->aif360[all]) (4.5.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter; extra == \"all\"->aif360[all]) (1.0.18)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (0.4.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (0.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (4.6.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (3.1.5)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (1.4.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter; extra == \"all\"->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter; extra == \"all\"->aif360[all]) (1.9.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter; extra == \"all\"->aif360[all]) (19.0.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter; extra == \"all\"->aif360[all]) (0.8.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.0.1)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from multiprocess->cvxpy>=1.0; extra == \"all\"->aif360[all]) (0.3.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from osqp>=0.4.1->cvxpy>=1.0; extra == \"all\"->aif360[all]) (0.16.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter; extra == \"all\"->aif360[all]) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter; extra == \"all\"->aif360[all]) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter; extra == \"all\"->aif360[all]) (0.7.5)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter; extra == \"all\"->aif360[all]) (2.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter; extra == \"all\"->aif360[all]) (0.2.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter; extra == \"all\"->aif360[all]) (0.5.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter; extra == \"all\"->aif360[all]) (0.6.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (3.1.0)\n",
            "Building wheels for collected packages: BlackBoxAuditing, lime, gast\n",
            "  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394767 sha256=f91cda48d93cdad7ee5b84ac2d57bc824473b145db37291d5bdb445ad90b6a73\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/82/7b/ac2a79b8caf97e15ed415162a7f272cbba1e2e2c851fa76ae3\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.0-cp36-none-any.whl size=284181 sha256=59da993ed5ac06c10f5b39b143ce88c45dc27f9a46603d8a10982efcae709cff\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/f2/ec/e5ebd07348b2b1ac722e91c2f549fcc220f7d5f25497a61232\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=3f34b65924c059db38042fbea9eb7792307600348c338e50f3fda744c94538ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built BlackBoxAuditing lime gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: adversarial-robustness-toolbox 1.2.0 has requirement Pillow==7.0.0, but you'll have pillow 5.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: adversarial-robustness-toolbox 1.2.0 has requirement scikit-learn==0.22.1, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sphinx-rtd-theme, BlackBoxAuditing, pillow, lime, adversarial-robustness-toolbox, tensorflow-estimator, tensorboard, gast, tensorflow, aif360\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed BlackBoxAuditing-0.1.54 adversarial-robustness-toolbox-1.2.0 aif360-0.3.0 gast-0.2.2 lime-0.2.0.0 pillow-5.4.1 sphinx-rtd-theme-0.4.3 tensorboard-1.15.0 tensorflow-1.15.3 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzyxxmGjzPvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "# Load all necessary packages\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
        "\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
        "\n",
        "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYJ15pfLzPvW",
        "colab_type": "text"
      },
      "source": [
        "#### Load dataset and set options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNRJoudyzPvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the dataset and split into train and test\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
        "\n",
        "!sudo cp adult.data /usr/local/lib/python3.6/dist-packages/aif360/data/raw/adult\n",
        "!sudo cp adult.test /usr/local/lib/python3.6/dist-packages/aif360/data/raw/adult\n",
        "!sudo cp adult.names /usr/local/lib/python3.6/dist-packages/aif360/data/raw/adult\n",
        "\n",
        "dataset_orig = load_preproc_data_adult()\n",
        "\n",
        "privileged_groups = [{'sex': 1}]\n",
        "unprivileged_groups = [{'sex': 0}]\n",
        "\n",
        "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWYGo4ujzPva",
        "colab_type": "code",
        "outputId": "25614383-31a1-4b37-c26c-f09d29cfe185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# print out some labels, names, etc.\n",
        "display(Markdown(\"#### Training Dataset shape\"))\n",
        "print(dataset_orig_train.features.shape)\n",
        "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
        "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
        "display(Markdown(\"#### Protected attribute names\"))\n",
        "print(dataset_orig_train.protected_attribute_names)\n",
        "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
        "print(dataset_orig_train.privileged_protected_attributes, \n",
        "      dataset_orig_train.unprivileged_protected_attributes)\n",
        "display(Markdown(\"#### Dataset feature names\"))\n",
        "print(dataset_orig_train.feature_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Training Dataset shape",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(34189, 18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Favorable and unfavorable labels",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.0 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Protected attribute names",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['sex', 'race']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Privileged and unprivileged protected attribute values",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Dataset feature names",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZFJHdBJzPvd",
        "colab_type": "text"
      },
      "source": [
        "#### Metric for original training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeW2BL9zzPve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Metric for the original dataset\n",
        "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Original training dataset\"))\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
        "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh-s1MHKzPvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_max_scaler = MaxAbsScaler()\n",
        "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
        "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
        "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                             unprivileged_groups=unprivileged_groups,\n",
        "                             privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
        "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
        "                             unprivileged_groups=unprivileged_groups,\n",
        "                             privileged_groups=privileged_groups)\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIiTX7gfzPvk",
        "colab_type": "text"
      },
      "source": [
        "### Learn plan classifier without debiasing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuNJ1DMdzPvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load post-processing algorithm that equalizes the odds\n",
        "# Learn parameters with debias set to False\n",
        "sess = tf.Session()\n",
        "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                          unprivileged_groups = unprivileged_groups,\n",
        "                          scope_name='plain_classifier',\n",
        "                          debias=False,\n",
        "                          sess=sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "r2vlMyFczPvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plain_model.fit(dataset_orig_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G66JqF5izPvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the plain model to test data\n",
        "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
        "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfoMUb3hzPvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Metrics for the dataset from plain model (without debiasing)\n",
        "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
        "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
        "\n",
        "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
        "\n",
        "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
        "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
        "                                                 dataset_nodebiasing_test,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
        "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
        "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAZNveRdzPvw",
        "colab_type": "text"
      },
      "source": [
        "### Apply in-processing algorithm based on adversarial learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btzba3gfzPvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close()\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0F7QkAozPvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Learn parameters with debias set to True\n",
        "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                          unprivileged_groups = unprivileged_groups,\n",
        "                          scope_name='debiased_classifier',\n",
        "                          debias=True,\n",
        "                          sess=sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "D1linJEgzPv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "debiased_model.fit(dataset_orig_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_cXWBTnzPv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the plain model to test data\n",
        "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
        "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e73Wi1ybzPv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Metrics for the dataset from plain model (without debiasing)\n",
        "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
        "\n",
        "# Metrics for the dataset from model with debiasing\n",
        "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
        "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
        "\n",
        "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
        "\n",
        "\n",
        "\n",
        "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
        "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
        "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
        "\n",
        "\n",
        "\n",
        "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
        "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
        "                                                 dataset_debiasing_test,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
        "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
        "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg3J743zzPv8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "    References:\n",
        "    [1] B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning,\" \n",
        "    AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQHTGVR9zPv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}